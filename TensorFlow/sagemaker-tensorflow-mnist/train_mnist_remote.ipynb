{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MNIST with SageMaker Cloud/Remote Execution\n",
    "\n",
    "This notebook demonstrates how to train a Tensorflow model using the AWS Sagemaker framework and deploy that model as an endpoint for inference. \n",
    "\n",
    "## Overview\n",
    "This example uses SageMaker's 'script mode' added after TensorFlow 1.11 that makes training a model on SageMaker very similar to running a script locally, or on Google Cloud AI Platform.\n",
    "\n",
    "The Tensorflow model you will be running in this example is located in training_job/task.py and training_job/model.py. The file task.py contains the driver loop for training the model.  The file model.py contains functions that define the model and the input function needed for reading the data. Without any changes you should be able to run task.py from the command line as a script.\n",
    "\n",
    "This notebook shows you how to run that same script locally using the TensorFlow Sagemaker Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "import numpy as np\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sagemaker.get_execution_role() function will identify the SageMaker role assigned to the SageMaker notebook\n",
    "# instance. This role has the necessary permissions required to run the training process.\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# The hyperparameters dictionary specified deploy contains parameters and hyperparamemters  that will be \n",
    "# sent to the command line of the script when the model is fit.\n",
    "hyperparameters={'steps':12000, # 600 steps per epoch, 20 epochs\n",
    "                  'batch-size':100,\n",
    "                  'learning-rate':0.001,\n",
    "                  'verbosity':'INFO'} \n",
    "\n",
    "\n",
    "# Here you are using the sagemaker.TensorFlow Python SDK to create a SageMaker estimator. \n",
    "#\n",
    "# Note: This example uses a CPU only instance ml.m4.xlarge. If you wish to use a GPU Instance \n",
    "# such as 'ml.p2.xlarge' you may need to request a quota increase\n",
    "# via http://aws.amazon.com/contact-us/ec2-request\n",
    "\n",
    "tf_estimator = TensorFlow(py_version='py3', \n",
    "                          framework_version='1.12', \n",
    "                          entry_point='task.py',\n",
    "                          role=role,\n",
    "                          train_instance_count=1,\n",
    "                          train_instance_type='ml.m4.xlarge',\n",
    "                          hyperparameters=hyperparameters,\n",
    "                          source_dir='trainer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the SageMaker estimator is created .fit() can be called on it.  The value for the key 'train' is set\n",
    "# to the environmet variable SM_CHANNEL_TRAIN and the key for 'eval' is set to the environment variable\n",
    "# SM_CHANNEL_EVAL. Your SageMaker script must implement these locations to find the model training and \n",
    "# eval data.\n",
    "\n",
    "# Calling fit.() in local mode will cause SageMaker to start a docker container on your machine \n",
    "# that contains the SageMaker TensorFlow training image. \n",
    "\n",
    "tf_estimator.fit({'train':'s3://sagemaker-us-east-2-708267171719/sagemaker/ml-model-migration/data/mnist/train',\n",
    "                  'eval':'s3://sagemaker-us-east-2-708267171719/sagemaker/ml-model-migration/data/mnist/test'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Endpoint Deployment\n",
    "\n",
    "Now that your model has been trained it can be deployed by calling .deploy() on the same Estimator instance we created above. The instance_type is set to the AWS machine type you would like to deploy to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "mnist_predictor = tf_estimator.deploy(initial_instance_count=1,\n",
    "                                      instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "Example 1: Predicted label: 2  Actual label:2\n",
      "Example 2: Predicted label: 1  Actual label:1\n",
      "Example 3: Predicted label: 0  Actual label:0\n",
      "Example 4: Predicted label: 4  Actual label:4\n",
      "Example 5: Predicted label: 1  Actual label:1\n",
      "Example 6: Predicted label: 4  Actual label:4\n",
      "Example 7: Predicted label: 9  Actual label:9\n",
      "Example 8: Predicted label: 5  Actual label:5\n",
      "Example 9: Predicted label: 9  Actual label:9\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "def load_mnist_data():   \n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = np.reshape(x_train, [-1, 28,28,1]).astype(np.float32)\n",
    "    x_test = np.reshape(x_test, [-1, 28,28,1]).astype(np.float32)\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    train_data = {'images':x_train, 'labels':y_train}\n",
    "    test_data = {'images':x_test, 'labels':y_test}\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = load_mnist_data()\n",
    "\n",
    "for ex in range(1,10):\n",
    "    # load an example from the test set\n",
    "    example = test_data['images'][ex].reshape(1,28,28,1)\n",
    "    #predictions is a dict{'predictions'[[]]}\n",
    "    predictions = mnist_predictor.predict(example)\n",
    "    #predictions['predictions'][0] contains the softmax activations of the network\n",
    "    predicted_label = np.argmax(predictions['predictions'][0])\n",
    "    label = test_data['labels'][ex]\n",
    "    print(\"Example {}: Predicted label: {}  Actual label:{}\".format(ex, predicted_label, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
